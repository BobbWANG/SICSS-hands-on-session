---
title: "Text analysis"
author: "Bo Wang"
date: '2022-06-06'
output: 
  md_document:
  variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Organizational Culture

Definition: Things that are valued or rewarded within a specific organization â€“ that is, the pattern of beliefs and expectations shared by members, and the behaviors that result from them.

## Organizational Culture Profile

Adaptability: being innovative, risk taking, being willing to experiment, fast moving, being quick to take advantage of opportunities, not being constrained by many rules

Integrity: having integrity, having high ethical standards, being honest, respecting individuals, being fair

Collaborative: working in collaboration with others, being team oriented, cooperative, being supportive, avoid conflict

Results oriented: being results oriented, having high expectations for performance, achievement

Customer oriented: being customer oriented, listening to customers, being market driven

Detail oriented: paying attention to detail, emphasizing quality, being precise

The original format of the scale is Q-sort task, which is relatively time- and energy-consuming for participants. Therefore, we decide to develop and validate more easy question formats: Likert scale item and point allocation task.

## A Pilot Study

313 participants and 60 job advertisements extracted from a professional recruitment website. After reading organization-related information from each job advertisement, participants rated the described organization on the six OCP organizational cultures and organizational attractiveness.

We calculated the validation coefficients for the different question formats. 

Generally, the different question format converged well with each other. Questions measuring the same culture dimension indicated high correlations than questions measuring different culture dimensions.

## I am Personally not Satisfied With the Validation Outcome 

We didnt' replicate the six organizational cultures by using the OCP following the original authors' procedure. 

One potential reason is that our sample size is not large enough.

Another reason would be that novel people's (employees') communication or experience of organizational cultures is different from employers'.

Whether the dimensions people use to communicate organizational cultures are different from the employers try to communicate in job advertisements?

I think the questions with different formats need a more validation step based on a relative large sample size having relatively good external validity. That is applying text mining techniques to job advertisements. 

## A New Validation Step by Using Structural Topic Modeling

We extracted more descriptions (around 2200 descriptions including the original sixty). I can compare the culture keywords from the OCP with the topic keywords returned by the STM.

Because the original 60 descriptions were rated by on average 10 raters, I can make use of these scores. For example, I can choose a description and see the extent to which the dominant topics (the keywords related to them) that the STM characterize converge with the its OCP culture scores.

The following are the concrete steps I took and some snapshoots of the results. During the analyssi, I encountered some problems that need your help and suggestions! 

### Read in data

```{r Load data file}
Organizaitonal_Culture <- readxl::read_xlsx("companies_2ndPartwith1ndPart60.xlsx",na = "",col_names = T, sheet = "Sheet2")
```

### Load packages for data analysis
```{r Load environment for text analysis, results = FALSE}
library(stm)
```

### Preprocess the documents
```{r Preprocess the documents}
Organizaitonal_culture_Preprocessed <- textProcessor(Organizaitonal_Culture$company_description, metadata = Organizaitonal_Culture,
lowercase = TRUE,
removestopwords = TRUE,
removenumbers = TRUE,
removepunctuation = TRUE,
ucp = FALSE,
stem = TRUE,
wordLengths = c(3, Inf),
sparselevel = 1,
language = "en",
verbose = TRUE,
onlycharacter = FALSE,
striphtml = FALSE,
customstopwords = c("company"),
custompunctuation = NULL,
v1 = FALSE) 
```

### Plot the number of words and documents removed for different thresholds
```{r}
plotRemoved(Organizaitonal_culture_Preprocessed$documents, lower.thresh = seq(1, 201, by = 10))
```

### Select a threshold and preprocess the documents
Qeustions: What are your suggestions for selecting a reasonable threshold? 
Setting the threshold as 24 (1% of the number of the total documents)
```{r}
output_thresh24 <- prepDocuments(Organizaitonal_culture_Preprocessed$documents, Organizaitonal_culture_Preprocessed$vocab, lower.thresh = 24)
```

Setting the threshold as 117 (1% of the number of the total documents)
```{r}
output_thresh117 <- prepDocuments(Organizaitonal_culture_Preprocessed$documents, Organizaitonal_culture_Preprocessed$vocab, lower.thresh = 117)
```

### Model selection and search
Searching when setting the threshold as 24.
```{r}
model_search_thresh24 <- searchK(output_thresh24$documents, out$vocab, K = (2:50), proportion = 0.3, heldout.seed = 666666, cores = 5)
```

### Plot of model selection results
Semantic coherence: the core idea is that in models which are semantically coherent the words which are most probable under a topic should co-occur within the same document.
Semantic exclusivity: The core idea is that the top words for a topic are unlikely to appear within top words of other topics.
These two indexes are usually negatively correlated so that a trade-off must be made.
#### Plot for the model selection results when the threshold is 24 documents.
```{r}
plot(model_search_thresh24)
```

Searching when setting the threshold as 117.
```{r}
model_search_thresh117 <- searchK(output_thresh117$documents, output_thresh117$vocab, K = (2:50), proportion = 0.3, heldout.seed = 666666, cores = 5)
```

### Plot for the model selection results when the threshold is 117 documents.
```{r}
plot(model_search_thresh117)
```
### Inspect the model indices 
#### when the threshold is 24
```{r}
model_indices_threshold24 <- as.data.frame(cbind(t(as.data.frame(model_search_thresh24[['results']]$K)), t(as.data.frame(model_search_thresh24[['results']]$exclus)), t(as.data.frame(model_search_thresh24[['results']]$semcoh))))
```

```{r}
model_indices_threshold24  %>% rename(Nnumber_of_topics = V1, semantic_coherence = V2, semantic_exclusivity = V3) %>% arrange(semantic_coherence)
```

#### when the threshold is 117
```{r}
model_indices_threshold117 <- as.data.frame(cbind(t(as.data.frame(model_search_thresh117[['results']]$K)), t(as.data.frame(model_search_thresh117[['results']]$exclus)), t(as.data.frame(model_search_thresh117[['results']]$semcoh))))
```

```{r}
model_indices_threshold117  %>% rename(Nnumber_of_topics = V1, semantic_coherence = V2, semantic_exclusivity = V3) %>% arrange(semantic_coherence)
```
